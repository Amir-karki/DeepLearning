{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7106a868-a132-4147-8494-ed27d131ea8d",
   "metadata": {},
   "source": [
    "<h4 style=\"color:green\">Stemming is the process of reducing a word to its base or root form — called the “stem.”\n",
    "\n",
    "The main goal is to remove suffixes and prefixes so that words with similar meanings are treated as the same term in text processing.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73900dd7-88ad-4f55-ae97-a903e6812663",
   "metadata": {},
   "source": [
    "#### Types of Stemmer:\n",
    "Porter Stemmer – Most popular; rule-based and aggressive.\n",
    "\n",
    "Regexp Stemmer: Looks for patterns at the end of words (like ing, ed, ly, etc.). Removes or replaces them using regex substitution rules.\n",
    "\n",
    "Snowball Stemmer – An improved version of Porter’s algorithm.\n",
    "\n",
    "Lancaster Stemmer – Even more aggressive; sometimes over-stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "057f40f3-bb2e-4730-99a7-192d72ff900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['play', 'plays', 'playing', 'player', 'played', 'study', 'studies', 'studying',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae27628-b348-4f43-a51f-4cde83aa8418",
   "metadata": {},
   "source": [
    "#### Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1081fe9d-1b73-4ee9-b2e0-c1f03099375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01f2db11-7329-4ba1-9bb3-e0ce0077766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play------>play\n",
      "plays------>play\n",
      "playing------>play\n",
      "player------>player\n",
      "played------>play\n",
      "study------>studi\n",
      "studies------>studi\n",
      "studying------>studi\n"
     ]
    }
   ],
   "source": [
    "stemming = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word + \"------>\" + stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb03a91-6b1c-4852-806f-18d50f692c78",
   "metadata": {},
   "source": [
    "##### PorterStemmer or Stemmer in general has some disadvantages. Sometimes the original meaning of the word is lost. For example: in our words list, the stem word of study, studies and studying is studi which has no meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9b0b5-1f36-4fd8-b1dc-22628e870a28",
   "metadata": {},
   "source": [
    "#### Regexp Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41fc3608-9d2e-424d-81a4-82fd926ab3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmer = RegexpStemmer(\"s$|y$|ing\", min=3) # min value applies that, stem will not be applied to words smaller than 3 chars\n",
    "stemmer.stem(\"studying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "337d7c62-7aa6-40f3-9c5c-f931d4001a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"ingplaying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb7330-34d2-404f-9212-56d57ed03332",
   "metadata": {},
   "source": [
    "#### Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c1256a3-aad4-4d2b-83ee-89a9ae13187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play----->play\n",
      "plays----->play\n",
      "playing----->play\n",
      "player----->player\n",
      "played----->play\n",
      "study----->studi\n",
      "studies----->studi\n",
      "studying----->studi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "for word in words:\n",
    "    print(word + \"----->\" + snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "591f8866-cf91-43e8-b056-dc48df577f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trek', 'trek')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('f'), snowball_stemmer.stem(\"treks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1541ca9-04be-44eb-9be1-aa3d06d7cd53",
   "metadata": {},
   "source": [
    "##### As we can see, snowball_stemmer is also not ideal, but it works better than PorterStemmer. For stem to work perfect, we use something called Lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b542a4-31e0-4a08-8d8e-243576aaf187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
